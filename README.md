# Intro

I am Jiecao YU, a PhD student in the University of Michigan.

This is a paper reading list about DNN acceleration (also general Deep Learning).

Still under construction.


# DNN Acceleration
## DNN architecture
- MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
[ [paper](https://arxiv.org/pdf/1704.04861.pdf) | 20170612001 ]
- LightRNN: Memory and Computation-Efficient Recurrent Neural Networks
[ [paper](https://arxiv.org/pdf/1610.09893.pdf) | 20170612005 ]
- ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
[ [paper](https://128.84.21.199/abs/1707.01083) | 20170713001 ]

## Accelerators
- Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators
[ [paper](http://vlsiarch.eecs.harvard.edu/wp-content/uploads/2016/05/reagen_isca16.pdf) | 20170630001 ]

## DNN pruning
- Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning
[ [paper](https://arxiv.org/pdf/1611.06440.pdf) | 20170612002 ]
- Learning Structured Sparsity in Deep Neural Networks
[ [paper](https://arxiv.org/pdf/1608.03665.pdf) | 20170612003 ]
- Dynamic Network Surgery for Efficient DNNs
[ [paper](https://arxiv.org/pdf/1608.04493.pdf) | 20170612004 ]
- Pruning Filters for Efficient ConvNets:
[ [paper](https://arxiv.org/pdf/1608.08710.pdf) | 20170901001 ]
- Data-Driven Sparse Structure Selection for Deep Neural Networks:
[ [paper](https://arxiv.org/pdf/1707.01213.pdf) | 20170901002 ]
- ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression:
[ [paper](http://lamda.nju.edu.cn/luojh/project/ThiNet_ICCV17/ThiNet_ICCV17.html) | 20170901003 ]
- Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism:
[ [paper](http://www-personal.umich.edu/~jiecaoyu/papers/jiecaoyu-isca17.pdf) | 20170901004 ]



# Others
